{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/NLU/nl-venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from functions import *\n",
    "from model import JointBert\n",
    "from utils import *\n",
    "\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_dev_data = load_data('dataset/ATIS/train.json')\n",
    "test_data = load_data('dataset/ATIS/test.json')\n",
    "train_raw, dev_raw, test_raw, y_train, y_dev, y_test = get_splits(train_dev_data, test_data)\n",
    "\n",
    "corpus = train_raw + dev_raw + test_raw # We do not wat unk labels, \n",
    "                                        # however this depends on the research purpose\n",
    "words = sum([x['utterance'].split() for x in train_raw], []) # No set() since we want to compute\n",
    "slots = set(sum([line['slots'].split() for line in corpus],[]))\n",
    "intents = set([line['intent'] for line in corpus])\n",
    "\n",
    "lang = Lang(words, intents, slots, cutoff=0)\n",
    "out_slot = len(lang.slot2id)\n",
    "out_int = len(lang.intent2id)\n",
    "\n",
    "\n",
    "train_dataset = IntentsAndSlots(train_raw, lang, tokenizer)\n",
    "dev_dataset = IntentsAndSlots(dev_raw, lang, tokenizer)\n",
    "test_dataset = IntentsAndSlots(test_raw, lang, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn,  shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "\n",
    "lr = 2e-5 # learning rate\n",
    "clip = 1.0 # Clip the gradient\n",
    "dropout = 0.1 # Dropout rate\n",
    "model = JointBert(config, out_slot, out_int, dropout=dropout).to(device)\n",
    "model.bert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion_slots = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = [17, 21, 25]\n",
    "path = 'bin/model{}.pth'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conll import evaluate\n",
    "import numpy as np\n",
    "def eval_loop(data, criterion_slots, criterion_intents, model, lang):\n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    ref_slots = []\n",
    "    hyp_slots = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    special_tokens = [tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id]\n",
    "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
    "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
    "        for sample in data:\n",
    "            input_ids, attention_mask, token_type_ids = sample['input_ids'].to(device), sample['attention_mask'].to(device), sample['token_type_ids'].to(device)\n",
    "            slot_labels = sample['slot_labels'].to(device)\n",
    "            intent_labels = sample['intent_labels'].to(device)\n",
    "            slots, intents = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss_intent = criterion_intents(intents, intent_labels)\n",
    "            loss_slot = criterion_slots(slots, slot_labels)\n",
    "            loss = loss_intent + loss_slot \n",
    "            loss_array.append(loss.item())\n",
    "\n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intent_labels'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            # Slot inference \n",
    "            output_slots = torch.argmax(slots, dim=1)\n",
    "            if -1 in output_slots:\n",
    "                print(\"Error in slot labels\")\n",
    "                print(output_slots.shape)\n",
    "                print(output_slots)\n",
    "\n",
    "            # check this part\n",
    "            for id_seq, seq in enumerate(output_slots):\n",
    "                mask = ~np.isin(slot_labels[id_seq].cpu().numpy(), special_tokens)\n",
    "                indices = list(np.where(mask)[0])\n",
    "                utt_ids = [input_ids[id_seq][i].item() for i in indices]\n",
    "                gt_ids = [slot_labels[id_seq][i].item() for i in indices]\n",
    "                gt_slots = [lang.id2slot[x] for x in gt_ids]\n",
    "                utterance = tokenizer.convert_ids_to_tokens(utt_ids)\n",
    "                to_decode = [seq[i].item() for i in indices]\n",
    "\n",
    "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
    "                tmp_seq = []\n",
    "                for id_el, elem in enumerate(to_decode):\n",
    "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "                if len(ref_slots[id_seq]) != len(hyp_slots[id_seq]):\n",
    "                    print(\"Error in slot labels\")\n",
    "\n",
    "    try:            \n",
    "        results = evaluate(ref_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predicts a class that is not in REF\n",
    "        print(\"Warning:\", ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        results = {\"total\":{\"f\":0}}\n",
    "        \n",
    "    report_intent = classification_report(ref_intents, hyp_intents, \n",
    "                                          zero_division=False, output_dict=True)\n",
    "    return results, report_intent, loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import JointBert\n",
    "state_dict = torch.load(path.format(1))['model']\n",
    "model = JointBert(config, out_slot, out_int, dropout=dropout).to(device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import JointBert\n",
    "F1_scores = []\n",
    "intent_accuracies = []\n",
    "\n",
    "for i in range(0, 30):\n",
    "    model_state_dict, optim = torch.load(path.format(i))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    results_test, intent_results, _ = eval_loop(dev_loader, criterion_slots, criterion_intents, model, lang)\n",
    "\n",
    "    F1_scores.append(results_test['total']['f'])\n",
    "    intent_accuracies.append(intent_results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abbreviation': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 15.0},\n",
       " 'aircraft': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 8.0},\n",
       " 'aircraft+flight+flight_no': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'airfare': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 42.0},\n",
       " 'airfare+flight': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'airfare+flight_time': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'airline': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 16.0},\n",
       " 'airline+flight_no': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'airport': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0},\n",
       " 'capacity': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 2.0},\n",
       " 'city': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0},\n",
       " 'distance': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 2.0},\n",
       " 'flight': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 367.0},\n",
       " 'flight+airfare': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 2.0},\n",
       " 'flight+airline': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'flight_no': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " 'flight_no+airline': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'flight_time': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 5.0},\n",
       " 'ground_fare': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 2.0},\n",
       " 'ground_service': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 25.0},\n",
       " 'ground_service+ground_fare': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'meal': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0},\n",
       " 'quantity': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 5.0},\n",
       " 'restriction': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " 'accuracy': 0.0,\n",
       " 'macro avg': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 498.0},\n",
       " 'weighted avg': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 498.0}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902,\n",
       "  0.011847361895577902],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_scores , intent_accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
